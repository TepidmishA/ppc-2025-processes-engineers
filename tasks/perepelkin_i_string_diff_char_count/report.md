# Подсчёт числа несовпадающих символов двух строк

- Студент: Перепелкин Ярослав Михайлович, группа 3823Б1ПР1
- Технологии: SEQ | MPI
- Вариант: 27

## 1. Введение
Алгоритм подсчёта несовпадающих символов в двух строках относится к классу задач обработки данных, хорошо поддающихся распараллеливанию благодаря независимости операций сравнения отдельных символов.

Цель работы – разработать параллельную MPI-реализацию данного алгоритма и провести сравнительный анализ её производительности с последовательной версией при различном количестве процессов.

## 2. Постановка задачи
**Определение задачи:**\
Для двух строк требуется вычислить количество позиций, в которых символы различаются. Если строки имеют разную длину, дополнительные символы более длинной строки учитываются как несовпадающие.

**Ограничения:**
- Входные данные – две строки произвольной длины.
- Алгоритм должен корректно обрабатывать строки разной длины.
- Учитывается регистр символов.
- Параллельная реализация использует MPI и должна поддерживать различное количество процессов.
- Результаты последовательной и параллельной версий должны быть идентичны.

## 3. Базовый алгоритм (последовательная версия)
**Входные данные:** две строки `s1` и `s2` произвольной длины.

**Выходные данные:** целое число – количество несовпадающих символов.

**Алгоритм последовательной реализации:**
1. Определить минимальную (`min_len`) и максимальную (`max_len`) длину строк.
2. Сравнить символы на одинаковых позициях в общей части строк (первые `min_len` символов) и подсчитать количество несовпадающих.
3. Добавить разницу длин строк (`max_len - min_len`) к результату – эти символы считаются несовпадающими, так как у них нет пар для сравнения.

**Сложность алгоритма:** `O(min(n,m))`, где `n` и `m` – длины строк `s1` и `s2` соответственно.

Реализация последовательного алгоритма представлена в Приложении 1.

## 4. Схема распараллеливания
Алгоритм параллельно вычисляет количество несовпадающих символов, распределяя обработку общей части строк между процессами и объединяя локальные результаты через коллективную операцию MPI.

### 4.1. Структура параллельного выполнения
- **Инициализация:** Все процессы запускаются в одном коммуникаторе `MPI_COMM_WORLD`.
- **Распределение данных:** Каждый процесс вычисляет границы своего сегмента сравнения. Распределение осуществляется с балансировкой нагрузки – первые `remainder` процессов получают один дополнительный элемент при неравномерном делении.
- **Локальные вычисления:** Каждый процесс независимо подсчитывает количество несовпадающих символов в назначенном ему сегменте.
- **Агрегация результатов:** Частичные результаты со всех процессов суммируются с помощью операции `MPI_Allreduce`.
- **Формирование итога:** К сумме различий в общей части строк добавляется разница их длин, и финальный результат становится доступен на всех процессах.

### 4.2. Организация процессов
- **Все процессы** выполняют вычисления на своих сегментах данных и участвуют в коллективной операции `MPI_Allreduce`.
- **Результат** глобального суммирования одновременно становится доступен на всех процессах.
- **Отсутствует центральный координатор** – все процессы равноправны в вычислительном процессе.

### 4.3. Псевдокод параллельной реализации
```cpp
bool RunImpl() {
    proc_rank = MPI_Comm_rank(MPI_COMM_WORLD)
    proc_num = MPI_Comm_size(MPI_COMM_WORLD)

    [s1, s2] = GetInput()
    len1 = s1.size(), len2 = s2.size()
    min_len = min(len1, len2), max_len = max(len1, len2)

    // Вычисление локального диапазона
    base_size = min_len / proc_num
    remainder = min_len % proc_num

    local_size = base_size + (proc_rank < remainder ? 1 : 0)
    local_start = proc_rank * base_size + min(proc_rank, remainder)
    local_end = local_start + local_size

    // Локальное сравнение символов
    local_diff = count_mismatches(s1, s2, local_start, local_end)

    // Глобальное суммирование
    global_diff = MPI_Allreduce(local_diff, SUM)

    // Учет разницы длин строк
    GetOutput() = global_diff + (max_len - min_len)
    return true
}
```

Реализация параллельного алгоритма представлена в Приложении 2.

## 5. Детали реализации

### 5.1. Структура кода
**Ключевые файлы проекта:**
```text
perepelkin_i_string_diff_char_count/
├── common/
│   └── include/common.hpp     - определения типов данных
├── data/                      - тестовые данные для функциональных тестов
├── mpi/
│   ├── include/ops_mpi.hpp    - заголовочный файл MPI-реализации
│   └── src/ops_mpi.cpp        - исходный код параллельной версии
├── seq/
│   ├── include/ops_seq.hpp    - заголовочный файл последовательной версии
│   └── src/ops_seq.cpp        - исходный код последовательной версии
└── tests/
    ├── functional/
    │   └── main.cpp           - функциональные тесты
    └── performance/
        └── main.cpp           - тесты производительности
```

**Основные классы реализации:**
- `PerepelkinIStringDiffCharCountSEQ` – класс последовательной реализации алгоритма.
- `PerepelkinIStringDiffCharCountMPI` – класс параллельной реализации алгоритма.

**Тестовые классы:**
- `PerepelkinIStringDiffCharCountFuncTestProcesses` – класс функционального тестирования.
- `PerepelkinIStringDiffCharCountPerfTestProcesses` – класс тестирования производительности.

**Интерфейс методов реализации:**
- `RunImpl()` – основной метод, содержащий реализацию алгоритма.
- `ValidationImpl()` – проверка корректности начального состояния и входных параметров.
- `PreProcessingImpl()` – подготовительные операции с входными данными.
- `PostProcessingImpl()` – завершающая обработка результатов вычислений.

### 5.2. Особенности реализации и обработка граничных случаев
- **Разные длины строк:** Алгоритм корректно обрабатывает строки разной длины, учитывая дополнительные символы как несовпадающие.
- **Пустые строки:** Корректно обрабатываются пустые строки и их комбинации.
- **Регистр символов:** Учитывается различие между заглавными и строчными буквами.
- **Специальные символы:** Корректно обрабатываются пробелы, знаки препинания и другие специальные символы.
- **Символы UTF-8:** Алгоритм корректно работает с многобайтовыми символами UTF-8.

### 5.3. Использование памяти
- **Последовательная версия:** `O(N)` – для хранения исходных строк длины `N`.
- **Параллельная версия:** `O(N × P)` – каждый из `P` процессов хранит полные копии строк длины `N`.
- **Обмен данными:** `O(P)` – для операции `MPI_Allreduce` передается одно целое число на процесс.

## 6. Тестовая инфраструктура

### 6.1. Аппаратное обеспечение:
| Параметр | Значение                                            |
| -------- | --------------------------------------------------- |
| CPU      | Intel Core i5-12400 (6 cores, 12 threads, 2.50 GHz) |
| RAM      | 32 GB DDR4 (3200 MHz)                               |
| OS       | Windows 11 Home 23H2 (22631.6060)                   |

### 6.2. Программное обеспечение:
| Параметр   | Значение                    |
| ---------- | --------------------------- |
| Компилятор | g++ 14.2.0                  |
| MPI        | Microsoft MPI 10.1.12498.52 |
| Сборка     | Release                     |

### 6.3. Тестовые данные
**Функциональные тесты:** используют заранее подготовленные наборы данных из директории `data/`, содержащие пары строк для сравнения с известным количеством несовпадающих символов.

**Тесты производительности:** данные генерируются программно по следующему алгоритму:
1. Создать 2 базовые строки длиной `N` символов.
2. Внести случайные различия с вероятностью 10%.
3. Масштабировать строки в `M` раз.
4. Добавить разницу длин 0.1%.

Реализация генерации тестовых данных представлена в Приложении 3.

## 7. Результаты и обсуждение

### 7.1 Корректность
Для проверки корректности работы алгоритма проводилось функциональное тестирование на основе Google Test Framework, которое включало:
- Проверку соответствия результатов заранее определённым ожидаемым значениям.
- Анализ работы алгоритма на граничных случаях:
  - Пустые строки и строки разной длины.
  - Учет регистра символов.
  - Обработка специальных символов.
  - Поддержка многобайтовых символов UTF-8.

**Перечень функциональных тестов:**
| Описание теста  | Файл с данными | Ожидаемое количество несовпадающих символов |
| ---------- | -------- |--|
| Первая строка пустая | `first_empty.txt` | 6 |
| Вторая строка пустая | `second_empty.txt` | 6 |
| Обе строки пустые | `empty_strings.txt` | 0 |
| Идентичные короткие строки | `identical_short.txt` | 0 |
| Один несовпадающий символ | `single_diff.txt` | 1 |
| Строки разной длины | `diff_length_extra_chars.txt` | 1 |
| Полностью различные строки | `completely_different.txt` | 4 |
| Строки с пробелами | `with_spaces.txt` | 2 |
| Учет регистра символов | `case_sensitive.txt` | 1 |
| Длинные строки с частичными различиями | `long_strings_partial_diff.txt` | 1 |
| Длинные строки с различиями в конце | `long_diff_tail.txt` | 3 |
| Специальные символы | `special_chars.txt` | 1 |
| Строки разной длины с многобайтовыми символами UTF-8 | `mixed_length_utf8.txt` | 1 |

Результаты функционального тестирования подтвердили корректность реализации алгоритма – все тестовые сценарии были успешно пройдены.

### 7.2 Производительность

**Параметры тестирования:**
- **Данные:** 2 строки длиной 1024 миллиона символов.
- **Метрики:**
  - Абсолютное время выполнения.
  - Ускорение относительно последовательной версии.
  - Эффективность параллелизации – рассчитывается как `(ускорение / количество процессов) × 100%`.
- **Сценарии измерения:**
  - **Полный цикл (pipeline)** – измерение времени выполнения всей программы (`Validation`, `PreProcessing`, `RunImpl`, `PostProcessing`).
  - **Только вычислительная часть (task_run)** – измерение времени только этапа выполнения алгоритма (`RunImpl`).

**Результаты полного цикла выполнения:**
| Режим | Процессы | Время, с | Ускорение | Эффективность |
| ----- | -------- | -------- | --------- | ------------- |
| seq   | 1        | 3.024638 | 1.000     | N/A           |
| mpi   | 2        | 1.636426 | 1.848     | 92.40%        |
| mpi   | 4        | 0.999760 | 3.025     | 75.63%        |

**Результаты вычислительной части:**
| Режим | Процессы | Время, с | Ускорение | Эффективность |
| ----- | -------- | -------- | --------- | ------------- |
| seq   | 1        | 3.022279 | 1.000     | N/A           |
| mpi   | 2        | 1.643281 | 1.839     | 91.95%        |
| mpi   | 4        | 1.016092 | 2.974     | 74.35%        |

**Анализ результатов (на основе сценария task_run):**
- **Производительность:** На 2 процессах наблюдается близкое к линейному ускорение (1.84×), однако на 4 процессах скорость роста производительности замедляется (2.97×).
- **Эффективность параллелизации:** На 2 процессах достигается высокий показатель эффективности в 92%, который снижается до 74% на 4 процессах из-за роста коммуникационных затрат.
- **Ограничения:** Необходимость хранения полных копий строк в каждом процессе создает повышенные требования к оперативной памяти.

## 8. Выводы
**Реализация и тестирование:**
- Успешно разработаны последовательная и параллельная MPI-реализации алгоритма подсчёта несовпадающих символов двух строк.
- Проведенное функциональное тестирование подтвердило корректность работы обеих версий на различных наборах данных.

**Эффективность параллелизации:**
- Достигнуто близкое к линейному ускорение при использовании 2 процессов (1.84×).
- При масштабировании до 4 процессов сохраняется значительное ускорение (2.97×) при снижении эффективности до 74%.

**Ограничения:**
- Основное ограничение – необходимость хранения полных копий строк в каждом процессе.
- Коммуникационные затраты снижают эффективность при увеличении числа процессов.

## 9. Источники
1. Документация по курсу «Параллельное программирование» // Parallel Programming Course URL: https://learning-process.github.io/parallel_programming_course/ru/index.html (дата обращения: 31.10.2025).
2. Сысоев А. В. «Коллективные и парные взаимодействия» // Лекции по дисциплине «Параллельное программирование для кластерных систем». — 2025.
3. Коллективные функции MPI // Microsoft URL: https://learn.microsoft.com/ru-ru/message-passing-interface/mpi-collective-functions (дата обращения: 01.11.2025).
4. std::transform_reduce // cppreference.com URL: https://en.cppreference.com/w/cpp/algorithm/transform_reduce.html (дата обращения: 09.11.2025).

## Приложения

### Приложение №1. Реализация последовательной версии алгоритма.
```cpp
bool PerepelkinIStringDiffCharCountSEQ::RunImpl() {
  const auto &[s1, s2] = GetInput();
  const size_t min_len = std::min(s1.size(), s2.size());
  const size_t max_len = std::max(s1.size(), s2.size());

  int diff = std::transform_reduce(s1.begin(), s1.begin() + min_len, s2.begin(), 0,
                                   std::plus<>(), std::not_equal_to<>());

  GetOutput() = diff + static_cast<int>(max_len - min_len);
  return true;
}
```

### Приложение №2. Реализация параллельной версии алгоритма.
```cpp
bool PerepelkinIStringDiffCharCountMPI::RunImpl() {
  int proc_rank = 0;
  int proc_num = 0;
  MPI_Comm_rank(MPI_COMM_WORLD, &proc_rank);
  MPI_Comm_size(MPI_COMM_WORLD, &proc_num);

  const auto &[s1, s2] = GetInput();
  const size_t len1 = s1.size();
  const size_t len2 = s2.size();
  const size_t min_len = std::min(len1, len2);
  const size_t max_len = std::max(len1, len2);

  const size_t base_size = min_len / proc_num;
  const int remainder = static_cast<int>(min_len % proc_num);

  // Calculate local range for this process
  const size_t local_size = base_size + (proc_rank < remainder ? 1 : 0);
  const size_t local_start = (proc_rank * base_size) + std::min(proc_rank, remainder);
  const size_t local_end = local_start + local_size;

  // Compute local number of differing characters
  auto s1_start = s1.begin() + static_cast<std::string::difference_type>(local_start);
  auto s1_end = s1.begin() + static_cast<std::string::difference_type>(local_end);
  auto s2_start = s2.begin() + static_cast<std::string::difference_type>(local_start);
  int local_diff = std::transform_reduce(s1_start, s1_end, s2_start, 0, std::plus<>(), std::not_equal_to<>());

  // Reduce (sum) differences for the common parts
  int global_diff = 0;
  MPI_Allreduce(&local_diff, &global_diff, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

  GetOutput() = global_diff + static_cast<int>(max_len - min_len);
  return true;
}
```

### Приложение №3. Генерация тестовых данных для тестов производительности
```cpp
 static std::tuple<std::string, std::string, int> GenerateTestData(size_t base_length, unsigned int seed,
                                                                    float diff_rate = 0.15F, int scale_factor = 1) {
    std::mt19937 gen(seed);

    std::string base_str1;
    std::string base_str2;
    base_str1.reserve(base_length);
    base_str2.reserve(base_length);

    const std::string charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789";
    std::uniform_int_distribution<size_t> char_dist(0, charset.size() - 1);
    std::uniform_real_distribution<double> diff_dist(0.0, 1.0);

    int base_diff_count = 0;

    // Generate base pattern
    for (size_t i = 0; i < base_length; ++i) {
      char c1 = charset[char_dist(gen)];
      base_str1.push_back(c1);

      if (diff_dist(gen) < diff_rate) {
        char c2 = charset[char_dist(gen)];
        while (c2 == c1) {
          c2 = charset[char_dist(gen)];
        }
        base_str2.push_back(c2);
        base_diff_count++;
      } else {
        base_str2.push_back(c1);
      }
    }

    // Scale strings by repeating the base pattern
    std::string str1;
    std::string str2;
    size_t scaled_length = base_length * scale_factor;
    str1.reserve(scaled_length);
    str2.reserve(scaled_length);

    for (int i = 0; i < scale_factor; ++i) {
      str1 += base_str1;
      str2 += base_str2;
    }
    int total_diff_count = base_diff_count * scale_factor;

    // Extend first string to be longer
    size_t extension_length = scaled_length / 1000;  // 0.1% extension
    for (size_t i = 0; i < extension_length; ++i) {
      str1.push_back(charset[char_dist(gen)]);
    }
    total_diff_count += static_cast<int>(extension_length);

    return {str1, str2, total_diff_count};
  }
```
